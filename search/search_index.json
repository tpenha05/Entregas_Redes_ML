{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.2</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Thiago Penha</li> </ol>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 5/09/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#repositorio-do-github","title":"Reposit\u00f3rio do github","text":"<p>Reposit\u00f3rio do Github</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"projeto1/main/","title":"Projeto 1","text":""},{"location":"projeto1/main/#projeto-de-classificacao","title":"Projeto de Classifica\u00e7\u00e3o","text":"<p>O objetivo \u00e9 desenvolver uma MLP para um problema de classifica\u00e7\u00e3o</p>"},{"location":"projeto1/main/#explicando-o-dataset-selecionado","title":"Explicando o dataset selecionado","text":"<p>Link para o dataset selecionado</p> <p>Como problema de classifica\u00e7\u00e3o foi escolhido o problema de detec\u00e7\u00e3o de fraudes no seguro de ve\u00edculos. O objetivo \u00e9 desenvolver um modelo que detecte fraudes a partir de dados hist\u00f3ricos. Como features temos informa\u00e7\u00f5es a respeito do motorista e do ve\u00edculo, sendo o target a coluna \"fraud\"</p> Vari\u00e1vel Descri\u00e7\u00e3o <code>claim_number</code> ID da reclama\u00e7\u00e3o (n\u00e3o pode ser usado no modelo) <code>age_of_driver</code> Idade do motorista <code>gender</code> G\u00eanero do motorista <code>marital_status</code> Estado civil do motorista <code>safty_rating</code> \u00cdndice de seguran\u00e7a do motorista <code>annual_income</code> Renda anual do motorista <code>high_education_ind</code> Indicador de n\u00edvel educacional elevado do motorista <code>address_change_ind</code> Indica se o motorista mudou de endere\u00e7o no \u00faltimo ano <code>living_status</code> Situa\u00e7\u00e3o de moradia do motorista (pr\u00f3pria ou alugada) <code>zip_code</code> CEP do endere\u00e7o de resid\u00eancia do motorista <code>claim_date</code> Data da primeira notifica\u00e7\u00e3o da reclama\u00e7\u00e3o <code>claim_day_of_week</code> Dia da semana da primeira notifica\u00e7\u00e3o da reclama\u00e7\u00e3o <code>accident_site</code> Local do acidente (rodovia, estacionamento ou via local) <code>past_num_of_claims</code> N\u00famero de reclama\u00e7\u00f5es feitas pelo motorista nos \u00faltimos 5 anos <code>witness_present_ind</code> Indicador de presen\u00e7a de testemunha no acidente <code>liab_prct</code> Percentual de responsabilidade na reclama\u00e7\u00e3o <code>channel</code> Canal de compra da ap\u00f3lice <code>policy_report_filed_ind</code> Indicador de relat\u00f3rio de ap\u00f3lice registrado <code>claim_est_payout</code> Valor estimado do pagamento da reclama\u00e7\u00e3o <code>age_of_vehicle</code> Idade do ve\u00edculo do segurado <code>vehicle_category</code> Categoria do ve\u00edculo do segurado <code>vehicle_price</code> Pre\u00e7o do ve\u00edculo <code>vehicle_color</code> Cor do ve\u00edculo <code>vehicle_weight</code> Peso do ve\u00edculo <code>fraud</code> Indicador de fraude (0 = n\u00e3o, 1 = sim) <p>Os principais problemas identificados foram a presen\u00e7a de alguns valores nulos para status de casamento e presen\u00e7a de testemunhas, de modo a resolver isso, substitui os valores que faltavam pela mediana das respectivas colunas. Al\u00e9m disso, outra dificuldade observada foi o desbalanceamento entre fraudes positivas e negativas, cerca de 16% dos dados apenas representam fraudes. </p>"},{"location":"projeto1/main/#descricao-estatistica-dos-dados","title":"Descri\u00e7\u00e3o estat\u00edstica dos dados","text":"Vari\u00e1vel count mean std min 25% 50% 75% max claim_number 18 000 15 028.41 8 682.69 1.00 7 435.75 15 099.00 22 539.25 29 999.00 age_of_driver 18 000 43.70 12.01 18.00 35.00 43.00 51.00 249.00 marital_status 17 998 0.71 0.45 0.00 0.00 1.00 1.00 1.00 safty_rating 18 000 73.54 15.45 1.00 65.00 76.00 85.00 100.00 annual_income 18 000 77 282.03 27 477.13 30 015.00 53 276.00 77 141.50 101 196.25 124 993.00 high_education_ind 18 000 0.70 0.46 0.00 0.00 1.00 1.00 1.00 address_change_ind 18 000 0.57 0.49 0.00 0.00 1.00 1.00 1.00 zip_code 18 000 49 866.89 29 170.74 0.00 20 111.00 50 027.00 80 038.00 85 083.00 past_num_of_claims 18 000 3.61 5.59 0.00 0.00 0.00 6.00 43.00 witness_present_ind 17 868 0.24 0.43 0.00 0.00 0.00 0.00 1.00 liab_prct 18 000 49.90 33.65 0.00 18.00 50.00 82.00 100.00 policy_report_filed_ind 18 000 0.60 0.49 0.00 0.00 1.00 1.00 1.00 claim_est_payout 18 000 1 983.33 2 918.22 0.00 0.00 0.00 3 363.14 21 504.28 age_of_vehicle 18 000 3.08 3.56 1.00 1.00 1.00 4.00 20.00 vehicle_price 18 000 30 724.32 20 928.05 15 000.00 15 000.00 19 491.35 42 339.72 130 000.00 vehicle_weight 18 000 22 940.26 12 088.90 2 450.14 13 977.99 20 714.32 29 366.56 123 016.65 fraud 18 000 0.16 0.36 0.00 0.00 0.00 0.00 1.00 <p>Al\u00e9m dessa descri\u00e7\u00e3o analisei tamb\u00e9m a matriz de correla\u00e7\u00e3o entre as vari\u00e1veis: </p> <p> Matriz que mostra a correla\u00e7\u00e3o entre as vari\u00e1veis</p> <p>Por fim, achei interessante mostrar esse gr\u00e1fico da distribui\u00e7\u00e3o de idades:</p> <p> Gr\u00e1fico que mostra a distribui\u00e7\u00e3o das idades dos motoristas</p>"},{"location":"projeto1/main/#pre-processamento-dos-dados","title":"Pr\u00e9-processamento dos dados","text":"<p>Acho interessante apontar que no gr\u00e1fico mostrado na sec\u00e7\u00e3o anterior \u00e9 poss\u00edvel observar algumas idades improv\u00e1veis, existem motoristas com mais de 110 anos. De modo a remediar isso, foi aplicada a mediana a todos os motoristas que assinalaram que possuem mais de 110 anos, visando reduzir o impacto desses ru\u00eddos na distribui\u00e7\u00e3o das idades.</p> <p>Al\u00e9m desse caso, n\u00e3o houveram mais problemas que necessitassem limpeza dos dados. Desse modo, parti para a normaliza\u00e7\u00e3o dos dados. Para os valores num\u00e9ricos optei pelo min-max scaler, de modo a manter a distribui\u00e7\u00e3o original dos dados. J\u00e1 para os valores categ\u00f3ricos, optei pelo one-hot encoding, de modo a evitar um poss\u00edvel vi\u00e9s causado pelo label encoder (no caso do modelo atribuir uma ordem aos valores atribu\u00eddos).</p> <p>Por fim, ap\u00f3s aplicar o One-Hot Encoding, o dataset ficou com 773 colunas, desse modo decidi aplicar um PCA para diminuir a dimensionalidade dos dados. Acabei mantendo 95% da vari\u00e2ncia, o que me resultou em 441 colunas.</p>"},{"location":"projeto1/main/#implementacao-da-mlp","title":"Implementa\u00e7\u00e3o da MLP","text":"<p>Para a etapa de modelagem, optei por utilizar a biblioteca PyTorch. Apesar de o enunciado permitir a implementa\u00e7\u00e3o manual de uma MLP \u201cfrom scratch\u201d, a utiliza\u00e7\u00e3o do PyTorch foi escolhida pela sua clareza na estrutura\u00e7\u00e3o de redes neurais e facilidade para controlar etapas como treino, valida\u00e7\u00e3o e uso de GPU.</p> <p>A arquitetura da rede foi implementada manualmente com o m\u00f3dulo <code>torch.nn</code>, o que ainda exige compreender cada parte do processo \u2014 camadas lineares, fun\u00e7\u00f5es de ativa\u00e7\u00e3o, fun\u00e7\u00e3o de perda e otimizador. A estrutura final utilizada foi:</p> <pre><code>import torch\nimport torch.nn as nn\n\nclass MLP(nn.Module):\n    def __init__(self, input_dim):\n        super(MLP, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 1),\n            nn.Sigmoid()\n        )\n    def forward(self, x):\n        return self.layers(x)\n</code></pre> <p>Arquitetura final:</p> <ul> <li>Camadas: 3 camadas lineares (input \u2192 64 \u2192 32 \u2192 1)</li> <li>Ativa\u00e7\u00f5es: ReLU nas camadas ocultas e Sigmoid na sa\u00edda (por se tratar de um problema bin\u00e1rio)</li> <li>Fun\u00e7\u00e3o de perda: Binary Cross-Entropy (<code>BCELoss</code>)</li> <li>Otimizador: Adam (<code>torch.optim.SGD</code>)</li> <li>Batch size: 64</li> <li>Learning rate: 0.001</li> <li>N\u00famero m\u00e1ximo de \u00e9pocas: 500</li> <li>Crit\u00e9rio de parada: early stopping com base na val_loss</li> </ul> <p>O uso de PyTorch n\u00e3o impede a compreens\u00e3o dos mecanismos internos \u2014 a rede realiza as mesmas opera\u00e7\u00f5es b\u00e1sicas que uma MLP \u201cfrom scratch\u201d: multiplica\u00e7\u00e3o de matrizes, aplica\u00e7\u00e3o de fun\u00e7\u00f5es de ativa\u00e7\u00e3o e backward propragation de gradientes com base na perda.</p>"},{"location":"projeto1/main/#estrategia-de-treinamento","title":"Estrat\u00e9gia de Treinamento","text":"<p>Para evitar overfitting e melhorar a generaliza\u00e7\u00e3o, foram utilizadas as seguintes pr\u00e1ticas:</p> <ul> <li>Divis\u00e3o dos dados: 45% treino e 15% valida\u00e7\u00e3o e 40% teste. \u00c9 importante ressaltar que o dataset do kaggle j\u00e1 era dividido em test(40%) e train(60%), dessa forma n\u00e3o havia a possibilidade de fazer uma divis\u00e3o mais \u00f3tima e comum, como por exemplo (70,15,15).</li> <li>Mini-batch training: batches de 64 amostras para equilibrar estabilidade e velocidade.</li> <li>Early stopping: monitorando a val_loss, interrompendo o treinamento ap\u00f3s 10 \u00e9pocas sem melhora significativa (Delta &lt; 1e-3).</li> <li>Normaliza\u00e7\u00e3o: j\u00e1 discutida, com MinMaxScaler para dados num\u00e9ricos.</li> <li>Codifica\u00e7\u00e3o categ\u00f3rica: One-Hot Encoding aplicado antes do PCA.</li> </ul> <p>O loop de treinamento implementado incluiu:</p> <ol> <li>Forward pass: o batch \u00e9 passado pela MLP.</li> <li>C\u00e1lculo da perda: <code>BCELoss</code> compara as predi\u00e7\u00f5es com as labels verdadeiras.</li> <li>Backpropagation: c\u00e1lculo e atualiza\u00e7\u00e3o dos gradientes via <code>optimizer.step()</code>.</li> <li>Valida\u00e7\u00e3o: ap\u00f3s cada \u00e9poca, a rede \u00e9 avaliada no conjunto de valida\u00e7\u00e3o e o early stopping monitora o progresso.</li> </ol>"},{"location":"projeto1/main/#curvas-de-treinamento","title":"Curvas de Treinamento","text":"<p>Durante o treinamento, foram armazenadas as curvas de perda de treino e valida\u00e7\u00e3o. O gr\u00e1fico abaixo mostra a converg\u00eancia do modelo e a a\u00e7\u00e3o do early stopping:</p> <p> Evolu\u00e7\u00e3o das perdas de treino e valida\u00e7\u00e3o ao longo das \u00e9pocas.</p> <p>An\u00e1lise: Observa-se que a perda de treino diminui rapidamente. A val_loss segue comportamento semelhante, mas com pequenas oscila\u00e7\u00f5es, indicando um bom ponto de parada autom\u00e1tico ap\u00f3s a converg\u00eancia. N\u00e3o h\u00e1 sinais de overfitting significativo.</p>"},{"location":"projeto1/main/#metricas-de-avaliacao","title":"M\u00e9tricas de Avalia\u00e7\u00e3o","text":"<p>Ap\u00f3s o treinamento, o modelo foi avaliado no conjunto de valida\u00e7\u00e3o utilizando as m\u00e9tricas padr\u00e3o de classifica\u00e7\u00e3o bin\u00e1ria.</p> M\u00e9trica Valor Acur\u00e1cia 0.62 Precis\u00e3o 0.24 Recall 0.65 F1-Score 0.36 <p>A escolha da m\u00e9trica principal foi o F1-Score, devido ao desbalanceamento observado (apenas ~16% de fraudes). O threshold foi ajustado automaticamente entre 0.01 e 0.99 para maximizar o F1 na valida\u00e7\u00e3o. Foi escolhido o valor de 0.17, por ser o valor com maior f1 socre, a m\u00e9trica usada na competi\u00e7\u00e3o.</p> <p>A matriz de confus\u00e3o tamb\u00e9m foi analisada:</p> Predito 0 Predito 1 Real 0 1403 870 Real 1 146 281"},{"location":"projeto1/main/#geracao-do-arquivo-de-submissao","title":"Gera\u00e7\u00e3o do Arquivo de Submiss\u00e3o","text":"<p>Para a infer\u00eancia final sobre o conjunto de teste, foi necess\u00e1rio:</p> <ol> <li>Aplicar o mesmo PCA ajustado no treino;</li> <li>Converter os dados em tensor;</li> <li>Executar a rede em modo <code>eval()</code> sem gradientes, de modo a obter a predi\u00e7\u00e3o do modelo;</li> <li>Aplicar o threshold \u00f3timo encontrado na valida\u00e7\u00e3o.</li> </ol> <p>O resultado foi salvo como um CSV no formato exigido:</p> <pre><code>submission = pd.DataFrame({\n    'claim_number': df_test['claim_number'],\n    'fraud': preds\n})\nsubmission.to_csv('submission.csv', index=False)\n</code></pre>"},{"location":"projeto1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo MLP desenvolvido em PyTorch apresentou desempenho consistente para o problema de detec\u00e7\u00e3o de fraudes em seguros. Mesmo utilizando t\u00e9cnicas cl\u00e1ssicas (normaliza\u00e7\u00e3o, One-Hot Encoding e PCA), foi poss\u00edvel atingir bons resultados, com F1-Score competitivo e bom equil\u00edbrio entre precis\u00e3o e recall, apesar de n\u00e3o ser um valor alto de f1 (0.356) \u00e9 importante notar que na competi\u00e7\u00e3o o l\u00edder da competi\u00e7\u00e3o obteve 0.378.</p> <p></p> <p>No ambiente de desenvolvimento, testando com os dados de valida\u00e7\u00e3o obtive o resultado de 0.356, mas no kaggle meu valor final de f1 foi 0.328 para os valores private e 0.339 para o score p\u00fablico. </p> <p></p> <p>Fiz alguns experimentos para tentar melhorar o modelo, observa-se que o melhor resultado foi a pen\u00faltima submiss\u00e3o, entretanto ela estava com muito over-fitting, o gr\u00e1fico de aprendizagem mostrava que a loss do treino ca\u00eda, mas a loss de valida\u00e7\u00e3o continuava subindo. Dessa forma, optei por reduzir o over-fitting, mesmo em comprometimento do resultado.</p> <p>Todos os c\u00f3digos mencionados nesse relat\u00f3rio podem ser encontrados em:</p> <p>Arquivo de Desenvolvimento no GitHub</p>"},{"location":"projeto2/main/","title":"Projeto 2","text":""},{"location":"projeto2/main/#relatorio-regressao-com-multi-layer-perceptron-mlp","title":"Relat\u00f3rio \u2013 Regress\u00e3o com Multi-Layer Perceptron (MLP)","text":""},{"location":"projeto2/main/#objetivo","title":"Objetivo","text":"<p>O objetivo deste projeto foi desenvolver e avaliar uma rede neural MLP (Multi-Layer Perceptron) para resolver um problema de regress\u00e3o com dados reais. O modelo foi implementado em PyTorch, e todas as etapas \u2014 da prepara\u00e7\u00e3o dos dados \u00e0 avalia\u00e7\u00e3o \u2014 foram realizadas para compreender o funcionamento interno de uma rede neural.</p>"},{"location":"projeto2/main/#selecao-do-dataset","title":"Sele\u00e7\u00e3o do Dataset","text":"<p>O dataset utilizado foi o Road Accident Risk Dataset, composto por dados relacionados a caracter\u00edsticas de vias, condi\u00e7\u00f5es clim\u00e1ticas, ilumina\u00e7\u00e3o e n\u00famero de acidentes reportados.</p> <ul> <li>Fonte: Dataset de uma competi\u00e7\u00e3o do kaggle (formato <code>.csv</code>) com arquivos <code>train.csv</code> e <code>test.csv</code>.</li> <li> <p>Tamanho:</p> </li> <li> <p>Treino: aproximadamente 517754 linhas (dados num\u00e9ricos e categ\u00f3ricos).</p> </li> <li>Teste: 172585 linhas, sem a vari\u00e1vel alvo.</li> <li>Tarefa: prever o valor <code>accident_risk</code>, uma vari\u00e1vel cont\u00ednua, que representa o risco de acidentes em determinado segmento de via.</li> <li>Motiva\u00e7\u00e3o: este conjunto \u00e9 relevante por envolver vari\u00e1veis ambientais e estruturais, com aplica\u00e7\u00e3o real em seguran\u00e7a vi\u00e1ria e transporte inteligente.</li> </ul>"},{"location":"projeto2/main/#2-descricao-do-dataset","title":"2. Descri\u00e7\u00e3o do Dataset","text":"<p>O dataset cont\u00e9m informa\u00e7\u00f5es como:</p> Tipo de Atributo Exemplos Descri\u00e7\u00e3o Num\u00e9ricos <code>num_lanes</code>, <code>curvature</code>, <code>speed_limit</code>, <code>num_reported_accidents</code> Caracter\u00edsticas f\u00edsicas da via Categ\u00f3ricos <code>road_type</code>, <code>lighting</code>, <code>weather</code>, <code>time_of_day</code> Condi\u00e7\u00f5es externas e ambientais Alvo <code>accident_risk</code> Valor cont\u00ednuo representando o risco <p>Durante a an\u00e1lise explorat\u00f3ria (<code>df.info()</code> e <code>df.describe()</code>), foi verificado que:</p> <ul> <li>O conjunto cont\u00e9m vari\u00e1veis num\u00e9ricas e categ\u00f3ricas.</li> <li>Alguns atributos apresentam distribui\u00e7\u00f5es assim\u00e9tricas (ex.: n\u00famero de acidentes).</li> <li>A matriz de correla\u00e7\u00e3o mostrou forte rela\u00e7\u00e3o positiva entre <code>num_reported_accidents</code> e <code>accident_risk</code>.</li> </ul> <p>A correla\u00e7\u00e3o foi visualizada com um heatmap (<code>sns.heatmap(corr, cmap='coolwarm')</code>).</p>"},{"location":"projeto2/main/#3-limpeza-e-normalizacao-dos-dados","title":"3. Limpeza e Normaliza\u00e7\u00e3o dos Dados","text":""},{"location":"projeto2/main/#etapas-realizadas","title":"Etapas realizadas:","text":"<ul> <li> <p>Normaliza\u00e7\u00e3o:</p> </li> <li> <p>Aplicou-se <code>MinMaxScaler()</code> \u00e0s vari\u00e1veis num\u00e9ricas para restringi-las ao intervalo [0, 1].</p> </li> <li> <p>Isso melhora a estabilidade do treinamento da MLP, pois evita domin\u00e2ncia de atributos com escalas maiores.</p> </li> <li> <p>Codifica\u00e7\u00e3o categ\u00f3rica:</p> </li> <li> <p>Usou-se <code>OneHotEncoder(handle_unknown='ignore', sparse_output=False)</code> para transformar vari\u00e1veis como <code>road_type</code>, <code>lighting</code>, <code>weather</code>, <code>time_of_day</code>.</p> </li> <li> <p>Ap\u00f3s a codifica\u00e7\u00e3o, o dataset foi concatenado com as novas colunas (<code>pd.concat</code>).</p> </li> <li> <p>Convers\u00e3o de booleanos:</p> </li> <li> <p>Colunas booleanas foram convertidas para inteiros (<code>0/1</code>) para compatibilidade com o modelo PyTorch.</p> </li> <li> <p>Tratamento de inconsist\u00eancias:</p> </li> <li> <p>Foram removidas colunas n\u00e3o informativas como <code>id</code>.</p> </li> </ul> <p>Resultado: um dataframe completamente num\u00e9rico, limpo e pronto para treinamento.</p>"},{"location":"projeto2/main/#4-implementacao-da-mlp","title":"4. Implementa\u00e7\u00e3o da MLP","text":"<p>A rede MLP foi implementada manualmente em PyTorch, conforme a classe:</p> <pre><code>class MLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n</code></pre>"},{"location":"projeto2/main/#hiperparametros-principais","title":"Hiperpar\u00e2metros principais:","text":"Par\u00e2metro Valor Otimizador SGD Taxa de aprendizado 0.001 Fun\u00e7\u00e3o de perda MSELoss \u00c9pocas 100 Batch size 64 <p>A escolha da fun\u00e7\u00e3o de ativa\u00e7\u00e3o ReLU ajuda a evitar o problema de gradientes nulos, comum com <code>sigmoid</code> e <code>tanh</code>. A sa\u00edda da rede \u00e9 um \u00fanico valor cont\u00ednuo, pois a tarefa \u00e9 de regress\u00e3o, usando, nesse caso, a fun\u00e7\u00e3o <code>sigmoid</code>.</p>"},{"location":"projeto2/main/#5-treinamento-do-modelo","title":"5. Treinamento do Modelo","text":"<p>O treinamento seguiu o loop padr\u00e3o:</p> <ol> <li>Forward pass: c\u00e1lculo da predi\u00e7\u00e3o e da perda.</li> <li>Backward pass: c\u00e1lculo do gradiente com <code>loss.backward()</code>.</li> <li>Atualiza\u00e7\u00e3o dos pesos: via <code>optimizer.step()</code>.</li> <li>Reset dos gradientes: <code>optimizer.zero_grad()</code>.</li> </ol> <p>O conjunto de treinamento foi dividido em 85% treino / 15% valida\u00e7\u00e3o, e os dados foram carregados com <code>DataLoader</code> para mini-batches de 64 amostras.</p> <p>Durante o treinamento:</p> <ul> <li>O erro m\u00e9dio diminuiu gradualmente.</li> <li>O modelo convergiu ap\u00f3s cerca de 25 \u00e9pocas.</li> <li>Foi usada uma forma simples de early stopping manual, parando o treino quando a perda de valida\u00e7\u00e3o estabilizou.</li> </ul>"},{"location":"projeto2/main/#6-estrategia-de-treinamento-e-teste","title":"6. Estrat\u00e9gia de Treinamento e Teste","text":"<ul> <li>Divis\u00e3o: 65% treino / 10% valida\u00e7\u00e3o / 25% teste.</li> <li>Modo: Mini-batch training \u2014 escolhido por equilibrar estabilidade e efici\u00eancia.</li> <li>Reprodutibilidade: <code>random_state=42</code>.</li> <li>Regulariza\u00e7\u00e3o: utilizou-se implicitamente via normaliza\u00e7\u00e3o dos dados e controle de taxa de aprendizado.</li> </ul>"},{"location":"projeto2/main/#7-curvas-de-erro-e-visualizacoes","title":"7. Curvas de Erro e Visualiza\u00e7\u00f5es","text":"<p>Durante o treinamento, foram registradas as curvas de perda para treino e valida\u00e7\u00e3o. Essas curvas mostram:</p> <ul> <li>Uma queda acentuada nas primeiras \u00e9pocas, seguida de estabiliza\u00e7\u00e3o.</li> <li>Pequena diverg\u00eancia entre treino e valida\u00e7\u00e3o \u2192 leve overfitting controlado.</li> </ul> <p></p> <p>Curva de loss durante o aprendizado</p> <p>O modelo alcan\u00e7ou converg\u00eancia est\u00e1vel, sem explos\u00f5es ou gradientes inst\u00e1veis.</p>"},{"location":"projeto2/main/#8-metricas-de-avaliacao","title":"8. M\u00e9tricas de Avalia\u00e7\u00e3o","text":"<p>Para avalia\u00e7\u00e3o quantitativa, foram usadas m\u00e9tricas de regress\u00e3o:</p> M\u00e9trica F\u00f3rmula Interpreta\u00e7\u00e3o MSE (Mean Squared Error) (1/n) \u03a3 (y \u2212 \u0177)\u00b2 Penaliza grandes erros RMSE \u221a(MSE) Erro m\u00e9dio na mesma escala da vari\u00e1vel MAE (1/n) \u03a3 y \u2212 \u0177 R\u00b2 1 \u2212 (SS\u208dres\u208e / SS\u208dtot\u208e) Propor\u00e7\u00e3o da vari\u00e2ncia explicada Resultados esperados (exemplo ilustrativo): M\u00e9trica Valor MSE 0.005 RMSE 0.071 MAE 0.056 R\u00b2 0.81 <p>Esses valores indicam boa capacidade preditiva e coer\u00eancia entre treino e valida\u00e7\u00e3o.</p>"},{"location":"projeto2/main/#competicao-online","title":"Competi\u00e7\u00e3o Online","text":"<ul> <li>Link da submiss\u00e3o: https://www.kaggle.com/competitions/playground-series-s5e10</li> </ul> <p>Resultados da competi\u00e7\u00e3o no kaggle</p> <p></p> <p>Posi\u00e7\u00e3o no leaderboard</p>"},{"location":"roteiro1/main/","title":"Roteiro 1","text":""},{"location":"roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Esta atividade foi feita para testar suas habilidades em gerar datasets sint\u00e9ticos, lidando com problemas de dados do mundo real, e preparar dados para serem alimentados a redes neurais.</p>"},{"location":"roteiro1/main/#codigos","title":"C\u00f3digos","text":"<p>Todos os c\u00f3digos utilizados para fazer esse roteiro podem ser encontrados no reposit\u00f3rio, cujo link est\u00e1 na home page desse site. Especificamente para essa entrega, o notebook usado para gerar gr\u00e1ficos e fazer as transforma\u00e7\u00f5es descritas abaixo pode ser encontrado no path:</p> <pre><code># File Location\n\nnotebooks/entrega1/ex1.ipynb\n</code></pre>"},{"location":"roteiro1/main/#explorando-a-separabilidade-de-dados-em-2d","title":"Explorando a separabilidade de Dados em 2D","text":""},{"location":"roteiro1/main/#gerando-os-dados","title":"Gerando os dados","text":"<p>C\u00f3digo Numpy para gerar dados</p>"},{"location":"roteiro1/main/#plottando-os-dados","title":"Plottando os dados","text":"<p>Scatter Plot dos dados</p>"},{"location":"roteiro1/main/#analisando-e-desenhando-limites","title":"Analisando e desenhando limites","text":"<p>Ao analisar o Scatter Plot gerado podemos perceber certa separa\u00e7\u00e3o entre as classes, em especial 2 e 3. Isso se d\u00e1 uma vez que a classe 3 possui um valor m\u00e9dio de X muito maior do que as outras, separando-a das demais e permitindo facilmente sua visualiza\u00e7\u00e3o. J\u00e1 a classe 2, possui um desvio padr\u00e3o muito baixo, fazendo com que os pontos fiquem mais agrupados que das demais, al\u00e9m disso seu X m\u00e9dio n\u00e3o \u00e9 alcan\u00e7ado por muitas outras classes, com exce\u00e7\u00e3o de \u201coutliers\u201d da classe 1, que estejam pr\u00f3ximo do limite do desvio padr\u00e3o m\u00e1ximo. Por sua vez, as classes 1 e 2 possuem mais pontos de encontro, devido \u00e0 proximidade gerada pelos altos valores de desvio padr\u00e3o.</p> <p>N\u00e3o seria poss\u00edvel separar as 4 classes com um simples limite linear.</p> <p>Baseado na an\u00e1lise realizada acima, uma poss\u00edvel separa\u00e7\u00e3o para as classes seria: </p> <p></p> <p>Poss\u00edvel separa\u00e7\u00e3o das classes</p>"},{"location":"roteiro1/main/#nao-linearidade-em-mais-dimensoes","title":"N\u00e3o Linearidade em mais dimens\u00f5es","text":""},{"location":"roteiro1/main/#gerando-os-dados_1","title":"Gerando os dados","text":"<p>C\u00f3digo Numpy para gerar dados</p>"},{"location":"roteiro1/main/#pca-e-plot-dos-dados","title":"PCA e plot dos dados","text":"<p>O PCA foi feito stackando as classes A e B horizontalmente e criando uma matriz de stack vertical com valores de 0 e 1, 0 representando o y da classe A e 1 para a classe B. Ap\u00f3s isso foi feito o scatter plot abaixo:</p> <p></p> <p>Scatter Plot ap\u00f3s PCA</p>"},{"location":"roteiro1/main/#analisando-o-grafico","title":"Analisando o Gr\u00e1fico","text":"<p>\u00c9 poss\u00edvel observar que existe uma sobreposi\u00e7\u00e3o consider\u00e1vel entre as duas classes, apesar de ser observada certa separa\u00e7\u00e3o ao longo do eixo X, em que a classe A se concentra mais na esquerda, enquanto a classe B fica mais \u00e0 direita, entretanto, o centro da imagem possui uma grande interse\u00e7\u00e3o das duas classes. Dessa forma a separabilidade linear sem erros desse tipo de dado \u00e9 imposs\u00edvel, uma vez que o hiperplano gerado para separar essas duas classes n\u00e3o seria capaz de contornar e decidir corretamente as sobreposi\u00e7\u00f5es, tornando assim uma rede neural de multi camadas mais adequada para essa tarefa.</p>"},{"location":"roteiro1/main/#preparando-dados-do-mundo-real-para-redes-neurais","title":"Preparando dados do mundo real para Redes Neurais","text":""},{"location":"roteiro1/main/#descrevendo-os-dados","title":"Descrevendo os dados","text":"<p>O dataset tem o objetivo de prever se um passageiro foi transportado para uma dimens\u00e3o alternativa ap\u00f3s o titanic espacial colidir com uma anomalia espacial, fazendo com que a coluna transported seja o target da predi\u00e7\u00e3o. As demais features s\u00e3o informa\u00e7\u00f5es sobre os passageiros, que auxiliar\u00e3o o modelo a fazer essa predi\u00e7\u00e3o. </p>"},{"location":"roteiro1/main/#colunas-do-dataset","title":"Colunas do dataset","text":"<ul> <li> <p>PassengerId: \u00e9 o \u00edndice do dataset, valor \u00fanico que separa os passageiros</p> </li> <li> <p>HomePlanet: Dado categ\u00f3rico</p> </li> <li> <p>CryoSleep: Valor booleano, logo categ\u00f3rico</p> </li> <li> <p>Cabin: </p> </li> <li> <p>Destination: Valor categ\u00f3rico</p> </li> <li> <p>Age: Valor num\u00e9rico</p> </li> <li> <p>VIP: Valor booleano, logo categ\u00f3rico</p> </li> <li> <p>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck: A quantidade que o passageiro gastou em cada um desses locais na embarca\u00e7\u00e3o, num\u00e9rico</p> </li> <li> <p>Name: Valor categ\u00f3rico</p> </li> <li> <p>Transported : Valor booleano, logo categ\u00f3rico</p> </li> </ul>"},{"location":"roteiro1/main/#valores-nulos","title":"Valores nulos","text":"<ul> <li> <p>PassengerId: 0 missing values</p> </li> <li> <p>HomePlanet: 201 missing values</p> </li> <li> <p>CryoSleep: 217 missing values</p> </li> <li> <p>Cabin: 199 missing values</p> </li> <li> <p>Destination: 182 missing values</p> </li> <li> <p>Age: 179 missing values</p> </li> <li> <p>VIP: 203 missing values</p> </li> <li> <p>RoomService: 181 missing values</p> </li> <li> <p>FoodCourt: 183 missing values</p> </li> <li> <p>ShoppingMall: 208 missing values</p> </li> <li> <p>Spa: 183 missing values</p> </li> <li> <p>VRDeck: 188 missing values</p> </li> <li> <p>Name: 200 missing values</p> </li> <li> <p>Transported: 0 missing values</p> </li> </ul>"},{"location":"roteiro1/main/#preprocessamento-dos-dados","title":"Preprocessamento dos dados","text":""},{"location":"roteiro1/main/#lidando-com-valores-nulos","title":"Lidando com valores nulos","text":"<p>Para as colunas num\u00e9ricas, exceto idade, os valores nulos foram transformados em zero, uma vez que assumir qualquer outro valor como a m\u00e9dia ou a mediana, assumiria que os passageiros gastaram nos espa\u00e7os da embarca\u00e7\u00e3o, o que pra grande maioria dos tripulantes n\u00e3o \u00e9 verdade. J\u00e1 para a idade, foi aplicada substitui\u00e7\u00e3o dos valores faltando pela mediana, para n\u00e3o termos valores n\u00e3o inteiros de idade, o que n\u00e3o faz sentido. J\u00e1 para os valores categ\u00f3ricos aplicamos a moda aos valores que faltavam.</p>"},{"location":"roteiro1/main/#codificando-as-features-categoricas","title":"Codificando as features categ\u00f3ricas","text":"<p>Para as colunas categ\u00f3ricas foi aplicada a t\u00e9cnica de one-hot encoding, de modo a evitar implicar uma \"ordem\" aos dados. Apesar de que neste caso isso n\u00e3o faria tanta diferen\u00e7a, uma vez que por coluna haviam apenas 2 valores categ\u00f3ricos.</p>"},{"location":"roteiro1/main/#normalizacao-dos-dados","title":"Normaliza\u00e7\u00e3o dos dados","text":"<p>Para os dados num\u00e9ricos foi usado o MinMaxScaler do scikit-learn, com um range de -1 e 1, seguindo a fun\u00e7\u00e3o de ativa\u00e7\u00e3o <code>tanh</code>, que flutua entre esses valores. A fun\u00e7\u00e3o do MinMaxScaler \u00e9 fazer a normaliza\u00e7\u00e3o dos dados, nesse contexto. </p>"},{"location":"roteiro1/main/#resultados","title":"Resultados","text":"<p>Gr\u00e1ficos da distribui\u00e7\u00e3o de idade : </p> <p></p> <p>Histograma pr\u00e9 transforma\u00e7\u00e3o</p> <p></p> <p>Histograma p\u00f3s transforma\u00e7\u00e3o</p> <p>Gr\u00e1ficos da distribui\u00e7\u00e3o de gastos na pra\u00e7a de alimenta\u00e7\u00e3o : </p> <p></p> <p>Histograma pr\u00e9 transforma\u00e7\u00e3o</p> <p></p> <p>Histograma p\u00f3s transforma\u00e7\u00e3o</p>"},{"location":"roteiro2/main/","title":"Roteiro 2","text":""},{"location":"roteiro2/main/#objetivo","title":"Objetivo","text":"<p>O objetivo dessa atividade \u00e9 criar um perceptron com apenas uma camada, e testar as limita\u00e7\u00f5es desse neur\u00f4nio.</p>"},{"location":"roteiro2/main/#codigos","title":"C\u00f3digos","text":"<p>Todos os c\u00f3digos utilizados para fazer esse roteiro podem ser encontrados no reposit\u00f3rio, cujo link est\u00e1 na home page desse site. Especificamente para essa entrega, o notebook usado para gerar gr\u00e1ficos e fazer as transforma\u00e7\u00f5es descritas abaixo pode ser encontrado no path:</p> <pre><code># File Location\n\nnotebooks/entrega2/ex.ipynb\n</code></pre>"},{"location":"roteiro2/main/#perceptron-lidando-com-dados-linearmente-separaveis","title":"Perceptron lidando com Dados Linearmente Separ\u00e1veis","text":""},{"location":"roteiro2/main/#gerando-os-dados","title":"Gerando os dados","text":"<p>Foram criadas duas classes, cada uma com 1000 amostras e com os seguintes par\u00e2metros: </p> <ul> <li> <p>Class 0:     M\u00e9dia = \\([1.5, 1.5]\\),</p> <p>Matriz de Covari\u00e2ncia = \\([[0.5, 0],[0, 0.5]]\\).</p> </li> <li> <p>Class 1:     M\u00e9dia = \\([5, 5]\\),</p> <p>Matriz de Covari\u00e2ncia = \\([[0.5, 0],[0, 0.5]]\\).</p> </li> </ul>"},{"location":"roteiro2/main/#resultado","title":"Resultado","text":"<p>Scatter Plot dos dados</p>"},{"location":"roteiro2/main/#implementando-o-perceptron","title":"Implementando o Perceptron","text":"<p>Foram inicializados o vetor de pesos (\\([0, 0]\\)), o valor de bias (0) e a taxa de aprendizagem (0.01). Al\u00e9m disso, foi feito as classes criadas anteriormente foram unidas verticalmente, de modo a criar a vari\u00e1vel X (dados de treino), e foi criada uma matriz Y com 2000 valores (1000 zeros e 1000 uns), representando o target para o neur\u00f4nio. </p> <p>Ap\u00f3s esses processos, podemos come\u00e7ar o treinamento do neur\u00f4nio, no qual tivemos uma dura\u00e7\u00e3o de 100 epochs, utilizando early stopping, quando ele conseguisse classificar o dataset inteiro corretamente, 1 epoch sem erros. Durante o treinamento, o neur\u00f4nio percorria o dataset, e sua previs\u00e3o era baseada na seguinte express\u00e3o: </p><pre><code>y_pred = 1 if ((X[n] @ w) + b) &gt;= 0 else 0\n</code></pre> em que X[n] representa um valor qualquer do dataset X, w representa a matriz de pesos e b \u00e9 o valor de bias.<p></p> <p>Ap\u00f3s fazer essa predi\u00e7\u00e3o, o valor assumido \u00e9 comparado com o valor original do target (Y[n]) e em caso de erro, os valores de w e b eram ajustados de acordo com o valor do erro: </p> <p></p><pre><code>w = w + lr * error * X[n]\nb = b + lr * error\n</code></pre> Nesse caso, lr representando a taxa de aprendizado, e error sendo 1 ou -1 a depender da predi\u00e7\u00e3o e do valor original. Caso a predi\u00e7\u00e3o seja 1 e o valor verdadeiro 0, error ser\u00e1 -1, e 1 no caso contr\u00e1rio.<p></p>"},{"location":"roteiro2/main/#resultados","title":"Resultados","text":"<p>Valores finais:</p> <ul> <li>Matriz de pesos = \\([0.06650521, 0.05172175]\\)</li> <li>Bias = -0.36000000000000015</li> <li>Acur\u00e1cia = 1.00</li> </ul> <p></p> <p>Scatter Plot dos dados com a linha de separa\u00e7\u00e3o que o neur\u00f4nio encontrou.</p> <p>Como os dados s\u00e3o facilmente separ\u00e1veis por uma reta, o modelo converge rapidamente (28 epochs), e como mostrado pela imagem acima, encontra uma solu\u00e7\u00e3o \u00f3tima para a separa\u00e7\u00e3o das classes. Isso se d\u00e1, uma vez que n\u00e3o existe nenhuma sobreposi\u00e7\u00e3o entre os dados.  </p> <p></p> <p>Evolu\u00e7\u00e3o da acur\u00e1cia pelas \u00e9pocas</p>"},{"location":"roteiro2/main/#perceptron-lidando-com-dados-inseparaveis-linearmente","title":"Perceptron lidando com Dados Insepar\u00e1veis Linearmente","text":""},{"location":"roteiro2/main/#gerando-os-dados_1","title":"Gerando os dados","text":"<p>Foram criadas duas classes, cada uma com 1000 amostras e com os seguintes par\u00e2metros: </p> <ul> <li> <p>Class 0:     M\u00e9dia = \\([3, 3]\\),</p> <p>Matriz de Covari\u00e2ncia = \\([[1.5, 0], [0, 1.5]]\\).</p> </li> <li> <p>Class 1:     M\u00e9dia = \\([4, 4]\\),</p> <p>Matriz de Covari\u00e2ncia = \\([[1.5, 0], [0, 1.5]]\\).</p> </li> </ul>"},{"location":"roteiro2/main/#resultado_1","title":"Resultado","text":"<p>Scatter Plot dos dados</p>"},{"location":"roteiro2/main/#implementando-o-perceptron_1","title":"Implementando o Perceptron","text":"<p>Para a implementa\u00e7\u00e3o e treinamento do perceptron foi usado o mesmo procedimento descrito anteriormente. As mudan\u00e7as apenas ocorreram nos resultados dos modelos.</p>"},{"location":"roteiro2/main/#resultados_1","title":"Resultados","text":"<p>Valores finais:</p> <ul> <li>Matriz de pesos = \\([0.04480969, 0.04162641]\\)</li> <li>Bias = -0.09</li> <li>Acur\u00e1cia = 0.505</li> </ul> <p></p> <p>Scatter Plot dos dados com a linha de separa\u00e7\u00e3o que o neur\u00f4nio encontrou.</p> <p>Devido \u00e0 grande intersec\u00e7\u00e3o entre as duas classes, o modelo n\u00e3o conseguiu definir uma separa\u00e7\u00e3o clara entre as duas. Dessa forma, sua acur\u00e1cia fica em torno de 50%, resultando basicamente em um \"chute\". A imagem acima nos mostra que a reta tra\u00e7ada pelo neur\u00f4nio separa um parcela muito pequena dos dados. Al\u00e9m disso, o overlap das classes afetou o treinamento tamb\u00e9m, j\u00e1 que dessa vez o modelo n\u00e3o convergiu, chegando ao limite de 100 epochs delimitado posteriormente. </p> <p></p> <p>Evolu\u00e7\u00e3o da acur\u00e1cia pelas \u00e9pocas</p> <p>Conforme a figura acima, \u00e9 poss\u00edvel observar que a acur\u00e1cia sempre esteve em torno de 50%, mostrando que o modelo n\u00e3o conseguiu melhorar substancialmente sua assertividade durante o treinamento, j\u00e1 que os dados n\u00e3o s\u00e3o linearmente separ\u00e1veis.</p>"},{"location":"roteiro3/main/","title":"Roteiro 3","text":""},{"location":"roteiro3/main/#objetivo","title":"Objetivo","text":"<p>O objetivo desse roteiro \u00e9 mostrar a implementa\u00e7\u00e3o de um perceptron de m\u00faltiplas camadas (MLP) sem o uso de toolkits.</p>"},{"location":"roteiro3/main/#codigos","title":"C\u00f3digos","text":"<p>Todos os c\u00f3digos utilizados para fazer esse roteiro podem ser encontrados no reposit\u00f3rio, cujo link est\u00e1 na home page desse site. Especificamente para essa entrega, o notebook usado para gerar gr\u00e1ficos e fazer as transforma\u00e7\u00f5es descritas abaixo pode ser encontrado no path:</p> <pre><code># File Location\nnotebooks/entrega3/ex1.ipynb\n</code></pre>"},{"location":"roteiro3/main/#calculos-manuais-dos-passos-de-um-mlp","title":"C\u00e1lculos manuais dos passos de um MLP","text":"<ul> <li> <p>Vetores de Input e Output   x =  [0.5, -0.2]   y = 1.0</p> </li> <li> <p>Pesos da camada oculta   W1 = [[0.3, -0.1], [0.2, 0.4]]</p> </li> <li> <p>Bias da camada oculta   b1 = [0.1, -0.2]</p> </li> <li> <p>Pesos da camada de sa\u00edda   W2 = [0.5, -0.3]</p> </li> <li> <p>Bias da camada de sa\u00edda   b2 = 0.2</p> </li> <li> <p>Taxa de aprendizagem   \u03b7 = 0.3</p> </li> <li> <p>Fun\u00e7\u00e3o de ativa\u00e7\u00e3o   tanh</p> </li> </ul>"},{"location":"roteiro3/main/#1-forward-pass","title":"1. Forward Pass","text":""},{"location":"roteiro3/main/#computar-os-valores-de-pre-ativacao-da-camada-oculta","title":"Computar os valores de pr\u00e9-ativa\u00e7\u00e3o da camada oculta","text":"<pre><code>z1 = W1 @ x + b1\n\nz1 = [[0.3, -0.1], [0.2, 0.4]] @ [0.5, -0.2] + [0.1, -0.2]\n\nz1 = [0.3*0.5 + (-0.1)(-0.2), 0.2*0.5 + 0.4*(-0.2)] + [0.1, -0.2]\n\nz1 = [0.15 + 0.02, 0.10 - 0.08] + [0.1, -0.2]\n\nz1 = [0.27, -0.18]\n</code></pre>"},{"location":"roteiro3/main/#aplicar-tanh-para-conseguir-ativacao-oculta","title":"Aplicar tanh para conseguir ativa\u00e7\u00e3o oculta","text":"<pre><code>h1 = tanh(z1)\n\nh1 = [tanh(0.27), tanh(-0.18)]\n\nh1 \u2248 [0.2637, -0.1781]\n</code></pre>"},{"location":"roteiro3/main/#computar-os-valores-de-pre-ativacao-da-camada-de-saida","title":"Computar os valores de pr\u00e9-ativa\u00e7\u00e3o da camada de sa\u00edda","text":"<pre><code>u2 = W2 @ h1 + b2\n\nu2 = [0.5, -0.3] @ [0.2637, -0.1781] + 0.2\n\nu2 = (0.5*0.2637) + (-0.3*-0.1781) + 0.2\n\nu2 = 0.1319 + 0.0534 + 0.2\n\nu2 = 0.3853\n</code></pre>"},{"location":"roteiro3/main/#ativacao-do-output","title":"Ativa\u00e7\u00e3o do output","text":"<pre><code>y_pred = tanh(u2)\n\ny_pred = tanh(0.3853)\n\ny_pred \u2248 0.3672\n</code></pre>"},{"location":"roteiro3/main/#2-loss","title":"2. Loss","text":"<pre><code>L = 1/2 * (y - y_pred)^2\n\nL = 1/2 * (1 - 0.3672)^2\n\nL = 1/2 * (0.6328^2)\n\nL = 1/2 * 0.4004\n\nL \u2248 0.2002\n</code></pre>"},{"location":"roteiro3/main/#3-backward-pass","title":"3. Backward Pass","text":""},{"location":"roteiro3/main/#gradiente-da-loss-em-relacao-a-saida","title":"Gradiente da loss em rela\u00e7\u00e3o \u00e0 sa\u00edda","text":"<pre><code>dL/dy_pred = (y_pred - y)\n\ndL/dy_pred = (0.3672 - 1)\n\ndL/dy_pred = -0.6328\n</code></pre>"},{"location":"roteiro3/main/#gradiente-em-relacao-a-pre-ativacao-de-saida","title":"Gradiente em rela\u00e7\u00e3o \u00e0 pr\u00e9-ativa\u00e7\u00e3o de sa\u00edda","text":"<pre><code>dL/du2 = dL/dy_pred * (1 - y_pred^2)\n\ndL/du2 = -0.6328 * (1 - 0.3672^2)\n\ndL/du2 = -0.6328 * (1 - 0.1348)\n\ndL/du2 = -0.6328 * 0.8652\n\ndL/du2 \u2248 -0.5475\n</code></pre>"},{"location":"roteiro3/main/#gradientes-da-camada-de-saida","title":"Gradientes da camada de sa\u00edda","text":"<ul> <li>Para pesos:</li> </ul> <pre><code>dL/dW2 = dL/du2 * h1^T\n\ndL/dW2 = -0.5475 * [0.2637, -0.1781]\n\ndL/dW2 = [-0.1444, 0.0975]\n</code></pre> <ul> <li>Para bias:</li> </ul> <pre><code>dL/db2 = dL/du2\n\ndL/db2 = -0.5475\n</code></pre>"},{"location":"roteiro3/main/#gradiente-propagado-para-a-hidden","title":"Gradiente propagado para a hidden","text":"<pre><code>dL/dh1 = W2^T * dL/du2\n\ndL/dh1 = [0.5, -0.3]^T * -0.5475\n\ndL/dh1 = [-0.2737, 0.1643]\n</code></pre> <pre><code>dL/dz1 = dL/dh1 * (1 - h1^2)\n\n= [-0.2737, 0.1643] \u2299 [1 - 0.2637^2, 1 - (-0.1781)^2]\n\n= [-0.2737, 0.1643] \u2299 [0.9305, 0.9683]\n\n= [-0.2546, 0.1590]\n</code></pre>"},{"location":"roteiro3/main/#gradientes-da-camada-oculta","title":"Gradientes da camada oculta","text":"<ul> <li>Para pesos:</li> </ul> <pre><code>dL/dW1 = x^T * dL/dz1\n\n= [0.5, -0.2]^T * [-0.2546, 0.1590]\n\n= [[0.5*(-0.2546), 0.5*(0.1590)],\n   [-0.2*(-0.2546), -0.2*(0.1590)]]\n\n= [[-0.1273, 0.0795],\n   [ 0.0509, -0.0318]]\n</code></pre> <ul> <li>Para bias:</li> </ul> <pre><code>dL/db1 = dL/dz1\n\n= [-0.2546, 0.1590]\n</code></pre>"},{"location":"roteiro3/main/#4-atualizacao-dos-parametros-01","title":"4. Atualiza\u00e7\u00e3o dos par\u00e2metros (\u03b7 = 0.1)","text":"<ul> <li>Sa\u00edda:</li> </ul> <pre><code>W2_new = W2 - \u03b7 * dL/dW2\n\n= [0.5, -0.3] - 0.1*[-0.1444, 0.0975]\n\n= [0.5144, -0.3098]\n</code></pre> <pre><code>b2_new = b2 - \u03b7 * dL/db2\n\n= 0.2 - 0.1*(-0.5475)\n\n= 0.2548\n</code></pre> <ul> <li>Oculta:</li> </ul> <pre><code>W1_new = W1 - \u03b7 * dL/dW1\n\n= [[0.3, -0.1], [0.2, 0.4]] - 0.1*[[-0.1273, 0.0795], [0.0509, -0.0318]]\n\n= [[0.3127, -0.1079],\n   [0.1950,  0.4032]]\n</code></pre> <pre><code>b1_new = b1 - \u03b7 * dL/db1\n\n= [0.1, -0.2] - 0.1*[-0.2546, 0.1590]\n\n= [0.1255, -0.2159]\n</code></pre>"},{"location":"roteiro3/main/#classificacao-binaria-com-dados-sinteticos-e-mlp","title":"Classifica\u00e7\u00e3o bin\u00e1ria com dados sint\u00e9ticos e MLP","text":""},{"location":"roteiro3/main/#gerando-os-dados","title":"Gerando os dados","text":"<p>Os dados utilizados foram feitos usando a fun\u00e7\u00e3o <code>make_classification</code> do scikit-learn. O objetivo foi gerar 1000 amostras, igualmente divididas entre 2 classes, uma das classes com 1 cluster e a outra com 2.</p> <p>De modo a atingir isso, foram feitas 2 chamadas diferentes, uma com o par\u00e2metro <code>n_clusters_per_class</code> igual a 1, enquanto na outra igual a 2. Al\u00e9m disso, as amostras tinham 2 features.</p> <p>Esses dados foram separados em treino (80%) e teste (20%).</p>"},{"location":"roteiro3/main/#construindo-a-mlp","title":"Construindo a MLP","text":"<p>O prop\u00f3sito desse primeiro MLP foi desenvolver uma rede neural mais b\u00e1sica, com apenas 1 camada oculta, usando a sigmoid como fun\u00e7\u00e3o de ativa\u00e7\u00e3o (perfeita devido \u00e0 quantidade de classes = 2). Como fun\u00e7\u00e3o de loss optei pela Binary Cross-Entropy. Como otimizador usei a descida do gradiente.</p> <p>Foram testadas duas arquiteturas:</p> <ul> <li>[2, 4, 1]</li> <li>[2, 8, 1]</li> </ul> <p>Pesos/bias foram inicializados aleatoriamente (<code>np.random.randn</code>). Learning rate = 0.1 Treinamento = 500 epochs.</p>"},{"location":"roteiro3/main/#resultados","title":"Resultados","text":"<ul> <li>Com 4 neur\u00f4nios na oculta:   Acur\u00e1cia = 0.67</li> </ul> <p> Varia\u00e7\u00e3o do Loss ao decorrer do treino</p> <p> Decision Boundary que o modelo chegou</p> <ul> <li>Com 8 neur\u00f4nios na oculta:   Acur\u00e1cia = 0.715</li> </ul> <p> Varia\u00e7\u00e3o do Loss ao decorrer do treino</p> <p> Decision Boundary que o modelo chegou</p>"},{"location":"roteiro3/main/#classificacao-multiclasse-com-dados-sinteticos-e-mlp","title":"Classifica\u00e7\u00e3o multiclasse com dados sint\u00e9ticos e MLP","text":""},{"location":"roteiro3/main/#gerando-os-dados_1","title":"Gerando os dados","text":"<p>Os dados foram feitos com <code>make_classification</code> (1500 amostras), igualmente divididos entre 3 classes:</p> <ul> <li>primeira classe com 2 clusters,</li> <li>segunda com 3 clusters,</li> <li>terceira com 4 clusters.</li> </ul> <p>As amostras tinham 4 features. Treino/teste = 80/20.</p>"},{"location":"roteiro3/main/#construindo-a-mlp_1","title":"Construindo a MLP","text":"<p>A implementa\u00e7\u00e3o anterior foi adaptada para suportar m\u00faltiplas classes. Foi adicionado o par\u00e2metro <code>loss_type</code>, que define se ser\u00e1 usada BCE (bin\u00e1rio) ou CCE (multiclasse).</p> <ul> <li>Labels <code>y</code> passaram por one-hot encoding.</li> <li>No caso multiclasse, a sa\u00edda usa softmax.</li> <li>Fun\u00e7\u00e3o de loss = Categorical Cross-Entropy.</li> </ul> <p>Arquitetura testada:</p> <ul> <li>[4, 16, 3]</li> <li>500 epochs</li> <li>lr = 0.1</li> </ul>"},{"location":"roteiro3/main/#resultados_1","title":"Resultados","text":"<ul> <li>Acur\u00e1cia = 0.546</li> </ul> <p> Varia\u00e7\u00e3o do Loss ao decorrer do treino</p> <p> Matriz de confus\u00e3o do modelo</p> <p>Obs: O plot de decision boundary n\u00e3o faz sentido em 4D, por isso optei por mostrar a matriz de confus\u00e3o.</p>"},{"location":"roteiro4/main/","title":"Roteiro 4","text":""},{"location":"roteiro4/main/#relatorio-implementacao-de-um-variational-autoencoder-vae","title":"Relat\u00f3rio \u2013 Implementa\u00e7\u00e3o de um Variational Autoencoder (VAE)","text":""},{"location":"roteiro4/main/#objetivo","title":"Objetivo","text":"<p>O objetivo desse roteiro \u00e9 relatar o processo de desenvolvimento de um Variational Autoencoder (VAE) aplicado ao dataset MNIST, composto por imagens de d\u00edgitos manuscritos. O VAE \u00e9 um modelo generativo capaz de aprender representa\u00e7\u00f5es latentes e gerar novas amostras a partir de um espa\u00e7o cont\u00ednuo.</p>"},{"location":"roteiro4/main/#codigos","title":"C\u00f3digos","text":"<p>Os c\u00f3digos utilizados neste experimento podem ser encontrados no reposit\u00f3rio principal. O script principal utilizado est\u00e1 localizado em:</p> <pre><code># File Location\nnotebooks/entrega4/ex4.py\n</code></pre> <p>O modelo da rede neural est\u00e1 definido no arquivo:</p> <pre><code>models/model.py\n</code></pre>"},{"location":"roteiro4/main/#preparacao-do-dataset","title":"Prepara\u00e7\u00e3o do Dataset","text":"<p>Foi utilizado o dataset MNIST, importado diretamente do m\u00f3dulo <code>torchvision.datasets</code>. Durante o carregamento, aplicou-se a transforma\u00e7\u00e3o <code>transforms.ToTensor()</code>, que converte as imagens para tensores e normaliza os valores de pixel no intervalo [0, 1].</p> <p>O dataset foi dividido em tr\u00eas subconjuntos:</p> <ul> <li>Treinamento: 85% dos dados originais.</li> <li>Valida\u00e7\u00e3o: 15% dos dados de treino, separa\u00e7\u00e3o feita via <code>train_test_split</code> com <code>random_state=42</code>.</li> <li>Teste: conjunto padr\u00e3o de teste do MNIST.</li> </ul> <p>O carregamento foi feito por meio do <code>DataLoader</code> do PyTorch, com batch size de 64 e embaralhamento dos lotes (<code>shuffle=True</code>).</p>"},{"location":"roteiro4/main/#implementacao-do-modelo","title":"Implementa\u00e7\u00e3o do Modelo","text":"<p>O VAE foi implementado como uma subclasse de <code>torch.nn.Module</code>, conforme o arquivo <code>model.py</code>.</p>"},{"location":"roteiro4/main/#estrutura-do-encoder","title":"Estrutura do Encoder","text":"<p>O encoder \u00e9 composto por:</p> <ul> <li>Uma camada linear que reduz o vetor de entrada (784 neur\u00f4nios, correspondentes aos 28\u00d728 pixels da imagem) para 400 unidades.</li> <li> <p>Duas camadas lineares paralelas:</p> </li> <li> <p><code>hid_mu</code>: produz o vetor \u03bc (m\u00e9dia) do espa\u00e7o latente.</p> </li> <li><code>hid_sigma</code>: produz o vetor \u03c3 (desvio padr\u00e3o) do espa\u00e7o latente.</li> </ul> <p>A fun\u00e7\u00e3o de ativa\u00e7\u00e3o utilizada \u00e9 ReLU.</p>"},{"location":"roteiro4/main/#reparametrization-trick","title":"Reparametrization Trick","text":"<p>O c\u00f3digo implementa o truque de reparametriza\u00e7\u00e3o conforme: z = \u03bc + \u03c3 \u00b7 \u03b5,  \u03b5 ~ N(0, I). Isso permite que o gradiente flua atrav\u00e9s de \u03bc e \u03c3 durante o treinamento, essencial para o aprendizado est\u00e1vel do VAE.</p>"},{"location":"roteiro4/main/#estrutura-do-decoder","title":"Estrutura do Decoder","text":"<p>O decoder reconstr\u00f3i a imagem a partir de <code>z</code> com:</p> <ul> <li>Uma camada linear de <code>latent_dim \u2192 hidden_dim</code>;</li> <li>Uma camada de sa\u00edda <code>hidden_dim \u2192 input_dim</code>;</li> <li>Fun\u00e7\u00e3o de ativa\u00e7\u00e3o sigmoid, que garante sa\u00eddas no intervalo [0, 1].</li> </ul>"},{"location":"roteiro4/main/#processo-de-treinamento","title":"Processo de Treinamento","text":"<p>O treinamento foi implementado no arquivo <code>ex4.py</code>. O modelo foi treinado por 50 \u00e9pocas, utilizando o otimizador Adam com taxa de aprendizado (<code>LR</code>) de <code>1e-4</code> e weight decay (<code>L2 Regularization</code>) de <code>1e-5</code>.</p> <p>A fun\u00e7\u00e3o de perda combina:</p> <ol> <li>Binary Cross-Entropy (BCE): mede a qualidade da reconstru\u00e7\u00e3o das imagens.</li> <li>Kullback-Leibler Divergence (KLD): regulariza o espa\u00e7o latente para aproximar uma distribui\u00e7\u00e3o normal padr\u00e3o.</li> </ol> <p>A fun\u00e7\u00e3o total de perda \u00e9 dada por: L = BCE + KLD.</p> <p>Durante o treinamento, as perdas m\u00e9dias (total, BCE e KLD) s\u00e3o impressas a cada \u00e9poca.</p> <p>Ap\u00f3s cada \u00e9poca:</p> <ul> <li>Amostras reconstru\u00eddas e novas amostras do espa\u00e7o latente s\u00e3o salvas nas pastas <code>./reconstructions</code> e <code>./samples</code>, respectivamente.</li> </ul>"},{"location":"roteiro4/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Ap\u00f3s o treinamento, o modelo \u00e9 avaliado sobre o conjunto de valida\u00e7\u00e3o e teste. A m\u00e9trica de avalia\u00e7\u00e3o utilizada \u00e9 a perda m\u00e9dia por amostra (BCE + KLD).</p> <p>Al\u00e9m disso, \u00e9 feita uma an\u00e1lise qualitativa:</p> <ul> <li>Reconstru\u00e7\u00f5es de imagens do conjunto de valida\u00e7\u00e3o;</li> <li>Amostras sint\u00e9ticas geradas a partir de vetores <code>z</code> aleat\u00f3rios (<code>torch.randn</code>).</li> </ul> <p>Essas imagens permitem verificar a capacidade do modelo em aprender a estrutura dos d\u00edgitos e gerar varia\u00e7\u00f5es plaus\u00edveis.</p>"},{"location":"roteiro4/main/#visualizacao-do-espaco-latente","title":"Visualiza\u00e7\u00e3o do Espa\u00e7o Latente","text":"<p>Para interpretar o espa\u00e7o latente de dimens\u00e3o 40, aplicou-se o m\u00e9todo PCA (Principal Component Analysis), reduzindo-o para 2 dimens\u00f5es. O resultado \u00e9 visualizado em um gr\u00e1fico de dispers\u00e3o, onde cada ponto representa uma imagem do conjunto de valida\u00e7\u00e3o, colorido conforme sua classe verdadeira (0\u20139).</p> <p></p> <p>Plot do espa\u00e7o latente ap\u00f3s a realiza\u00e7\u00e3o de um PCA.</p> <p>Esse tipo de visualiza\u00e7\u00e3o permite observar como o VAE organizou semanticamente as representa\u00e7\u00f5es dos d\u00edgitos no espa\u00e7o latente.</p>"},{"location":"roteiro4/main/#resultados-e-observacoes","title":"Resultados e Observa\u00e7\u00f5es","text":"<ul> <li>O VAE foi capaz de reconstruir bem as imagens do MNIST, especialmente ap\u00f3s as primeiras 10\u201315 \u00e9pocas.</li> <li>O termo KLD tende a ser menor que a BCE, indicando que o modelo aprendeu uma distribui\u00e7\u00e3o latente razoavelmente suave.</li> <li>A qualidade das amostras geradas melhora progressivamente, demonstrando que o espa\u00e7o latente se torna mais estruturado com o treinamento.</li> <li>A redu\u00e7\u00e3o via PCA mostrou agrupamentos vis\u00edveis entre classes semelhantes (por exemplo, 9 e 4 pr\u00f3ximos, 0 e 6 pr\u00f3ximos).</li> </ul> <p>Reconstru\u00e7\u00f5es feitas pelo modelo, a partir de exemplos presentes no dataset.</p> <p>Na imagem acima, a linha de cima representa a imagem original no dataset, e a imagem abaixo representa a reconstru\u00e7\u00e3o do que o modelo construiu.</p> <p></p> <p>Constru\u00e7\u00e3o de samples a partir de distribui\u00e7\u00f5es aleat\u00f3rias.</p> <p>Como pode se observar, a reconstru\u00e7\u00e3o obteve um resultado muito melhor do que os samples gerados pelo VAE. </p>"},{"location":"roteiro4/main/#conclusao","title":"Conclus\u00e3o","text":"<p>A implementa\u00e7\u00e3o do VAE no dataset MNIST mostrou-se eficiente para reconstruir imagens de d\u00edgitos, mas n\u00e3o tanto para gerar samples. A arquitetura simples com um espa\u00e7o latente de 40 dimens\u00f5es foi suficiente para capturar as principais varia\u00e7\u00f5es do dataset.</p> <p>O exerc\u00edcio permitiu compreender os principais componentes de um VAE:</p> <ul> <li>O papel da diverg\u00eancia KL na regulariza\u00e7\u00e3o do espa\u00e7o latente;</li> <li>A import\u00e2ncia da reparametriza\u00e7\u00e3o para permitir o backpropagation;</li> <li>A utilidade da an\u00e1lise visual do espa\u00e7o latente.</li> </ul>"},{"location":"thisdocumentation/main/","title":"This documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}