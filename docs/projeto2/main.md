# Relat√≥rio ‚Äì Regress√£o com Multi-Layer Perceptron (MLP)

## Objetivo

O objetivo deste projeto foi desenvolver e avaliar uma **rede neural MLP (Multi-Layer Perceptron)** para resolver um problema de **regress√£o** com dados reais.
O modelo foi implementado em **PyTorch**, e todas as etapas ‚Äî da prepara√ß√£o dos dados √† avalia√ß√£o ‚Äî foram realizadas para compreender o funcionamento interno de uma rede neural.

---

## Sele√ß√£o do Dataset

O dataset utilizado foi o **Road Accident Risk Dataset**, composto por dados relacionados a caracter√≠sticas de vias, condi√ß√µes clim√°ticas, ilumina√ß√£o e n√∫mero de acidentes reportados.

* **Fonte:** Dataset de uma competi√ß√£o do kaggle (formato `.csv`) com arquivos `train.csv` e `test.csv`.
* **Tamanho:**

  * Treino: aproximadamente **517754 linhas** (dados num√©ricos e categ√≥ricos).
  * Teste: **172585 linhas**, sem a vari√°vel alvo.
* **Tarefa:** prever o valor **`accident_risk`**, uma vari√°vel **cont√≠nua**, que representa o risco de acidentes em determinado segmento de via.
* **Motiva√ß√£o:** este conjunto √© relevante por envolver **vari√°veis ambientais e estruturais**, com aplica√ß√£o real em **seguran√ßa vi√°ria e transporte inteligente**.

---

## üìò 2. Descri√ß√£o do Dataset

O dataset cont√©m informa√ß√µes como:

| Tipo de Atributo | Exemplos                                                          | Descri√ß√£o                            |
| ---------------- | ----------------------------------------------------------------- | ------------------------------------ |
| Num√©ricos        | `num_lanes`, `curvature`, `speed_limit`, `num_reported_accidents` | Caracter√≠sticas f√≠sicas da via       |
| Categ√≥ricos      | `road_type`, `lighting`, `weather`, `time_of_day`                 | Condi√ß√µes externas e ambientais      |
| Alvo             | `accident_risk`                                                   | Valor cont√≠nuo representando o risco |

Durante a an√°lise explorat√≥ria (`df.info()` e `df.describe()`), foi verificado que:

* O conjunto cont√©m **vari√°veis num√©ricas e categ√≥ricas**.
* Alguns atributos apresentam **distribui√ß√µes assim√©tricas** (ex.: n√∫mero de acidentes).
* A matriz de correla√ß√£o mostrou **forte rela√ß√£o positiva** entre `num_reported_accidents` e `accident_risk`.

A correla√ß√£o foi visualizada com um **heatmap** (`sns.heatmap(corr, cmap='coolwarm')`).

---

## 3. Limpeza e Normaliza√ß√£o dos Dados

### Etapas realizadas:

1. **Normaliza√ß√£o:**

   * Aplicou-se `MinMaxScaler()` √†s vari√°veis num√©ricas para restringi-las ao intervalo [0, 1].
   * Isso melhora a estabilidade do treinamento da MLP, pois evita domin√¢ncia de atributos com escalas maiores.

2. **Codifica√ß√£o categ√≥rica:**

   * Usou-se `OneHotEncoder(handle_unknown='ignore', sparse_output=False)` para transformar vari√°veis como `road_type`, `lighting`, `weather`, `time_of_day`.
   * Ap√≥s a codifica√ß√£o, o dataset foi concatenado com as novas colunas (`pd.concat`).

3. **Convers√£o de booleanos:**

   * Colunas booleanas foram convertidas para inteiros (`0/1`) para compatibilidade com o modelo PyTorch.

4. **Tratamento de inconsist√™ncias:**

   * Foram removidas colunas n√£o informativas como `id`.

Resultado: um dataframe completamente num√©rico, limpo e pronto para treinamento.

---

## 4. Implementa√ß√£o da MLP

A rede MLP foi implementada manualmente em **PyTorch**, conforme a classe:

```python
class MLP(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
    
    def forward(self, x):
        return self.layers(x)
```

### Hiperpar√¢metros principais:

| Par√¢metro           | Valor   |
| ------------------- | ------- |
| Otimizador          | SGD     |
| Taxa de aprendizado | 0.001   |
| Fun√ß√£o de perda     | MSELoss |
| √âpocas              | 100     |
| Batch size          | 64      |

A escolha da fun√ß√£o de ativa√ß√£o **ReLU** ajuda a evitar o problema de gradientes nulos, comum com `sigmoid` e `tanh`.
A sa√≠da da rede √© **um √∫nico valor cont√≠nuo**, pois a tarefa √© de **regress√£o**, usando, nesse caso, a fun√ß√£o `sigmoid`.

---

## 5. Treinamento do Modelo

O treinamento seguiu o loop padr√£o:

1. **Forward pass:** c√°lculo da predi√ß√£o e da perda.
2. **Backward pass:** c√°lculo do gradiente com `loss.backward()`.
3. **Atualiza√ß√£o dos pesos:** via `optimizer.step()`.
4. **Reset dos gradientes:** `optimizer.zero_grad()`.

O conjunto de treinamento foi dividido em **85% treino / 15% valida√ß√£o**, e os dados foram carregados com `DataLoader` para mini-batches de 64 amostras.

Durante o treinamento:

* O erro m√©dio diminuiu gradualmente.
* O modelo convergiu ap√≥s cerca de **25 √©pocas**.
* Foi usada uma forma simples de **early stopping manual**, parando o treino quando a perda de valida√ß√£o estabilizou.

---

## 6. Estrat√©gia de Treinamento e Teste

* **Divis√£o:** 65% treino / 10% valida√ß√£o / 25% teste.
* **Modo:** *Mini-batch training* ‚Äî escolhido por equilibrar estabilidade e efici√™ncia.
* **Reprodutibilidade:** `random_state=42`.
* **Regulariza√ß√£o:** utilizou-se implicitamente via normaliza√ß√£o dos dados e controle de taxa de aprendizado.

---

## 7. Curvas de Erro e Visualiza√ß√µes

Durante o treinamento, foram registradas as curvas de perda para treino e valida√ß√£o.
Essas curvas mostram:

* Uma **queda acentuada nas primeiras √©pocas**, seguida de estabiliza√ß√£o.
* Pequena diverg√™ncia entre treino e valida√ß√£o ‚Üí leve **overfitting controlado**.

![Plottando da curva de loss](./loss.png)
/// caption
Curva de loss durante o aprendizado
///

O modelo alcan√ßou **converg√™ncia est√°vel**, sem explos√µes ou gradientes inst√°veis.

---

## 8. M√©tricas de Avalia√ß√£o

Para avalia√ß√£o quantitativa, foram usadas m√©tricas de regress√£o:

| M√©trica                      | F√≥rmula                            | Interpreta√ß√£o                          |   |                     |
| ---------------------------- | ---------------------------------- | -------------------------------------- | - | ------------------- |
| **MSE** (Mean Squared Error) | ( \frac{1}{n}\sum(y - \hat{y})^2 ) | Penaliza grandes erros                 |   |                     |
| **RMSE**                     | ( \sqrt{MSE} )                     | Erro m√©dio na mesma escala da vari√°vel |   |                     |
| **MAE**                      | ( \frac{1}{n}\sum                  | y - \hat{y}                            | ) | Erro m√©dio absoluto |
| **R¬≤**                       | ( 1 - \frac{SS_{res}}{SS_{tot}} )  | Propor√ß√£o da vari√¢ncia explicada       |   |                     |

Resultados esperados (exemplo ilustrativo):

| M√©trica | Valor |
| ------- | ----- |
| MSE     | 0.005 |
| RMSE    | 0.071 |
| MAE     | 0.056 |
| R¬≤      | 0.81  |

Esses valores indicam **boa capacidade preditiva** e coer√™ncia entre treino e valida√ß√£o.

---
## Competi√ß√£o Online

* **Link da submiss√£o:** [https://www.kaggle.com/competitions/playground-series-s5e10](#)

![Submiss√£o no kaggle](./Captura%20de%20tela%202025-10-23%20193936.png)
/// caption
Resultados da competi√ß√£o no kaggle
///
![Resultados na competi√ß√£o](./Captura%20de%20tela%202025-10-23%20194054.png)
///caption
Posi√ß√£o no leaderboard
///